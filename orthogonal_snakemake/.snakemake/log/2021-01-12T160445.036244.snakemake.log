Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	subset
	1
Select jobs to execute...

[Tue Jan 12 16:04:45 2021]
rule subset:
    input: /home/rictuar/coding_projects/fiehn_work/text_files/orthogonal_snakemake/[M-H]-/qtof/precursor_yes/starting_files/overall_similarity_result_dot_product_[M-H]-.csv
    output: /home/rictuar/coding_projects/fiehn_work/text_files/orthogonal_snakemake/[M-H]-/qtof/precursor_yes/starting_files/similarity_subset_nist20_only_qtof_only_[M-H]-.txt
    jobid: 0
    wildcards: adduct=[M-H]-, instrument=qtof, precursor_status=precursor_yes

[Tue Jan 12 16:04:45 2021]
Finished job 0.
1 of 1 steps (100%) done
Complete log: /home/rictuar/coding_projects/fiehn_work/small_scripts/orthogonal_snakemake/.snakemake/log/2021-01-12T160445.036244.snakemake.log
